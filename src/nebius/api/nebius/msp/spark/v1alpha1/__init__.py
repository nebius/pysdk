# 
# Generated by the nebius.base.protos.compiler.  DO NOT EDIT!
# 

import nebius.base.protos.pb_classes as pb_classes
import nebius.api.nebius.msp.spark.v1alpha1.cluster_pb2 as cluster_pb2
import nebius.base.protos.descriptor as descriptor
import google.protobuf.descriptor as descriptor_1
import google.protobuf.message as message_1
import nebius.api.nebius.common.v1 as v1_1
import nebius.api.nebius.common.v1.metadata_pb2 as metadata_pb2
import builtins as builtins
import typing as typing
import nebius.api.nebius.msp.v1alpha1 as v1alpha1_1
import nebius.api.nebius.msp.v1alpha1.cluster_pb2 as cluster_pb2_1
import nebius.api.nebius.msp.spark.v1alpha1.cluster_service_pb2 as cluster_service_pb2
import collections.abc as abc
import nebius.aio.client as client
import grpc as grpc
import nebius.aio.request as request_1
import nebius.aio.operation as operation
import nebius.api.nebius.common.v1.operation_pb2 as operation_pb2
import nebius.api.nebius.msp.spark.v1alpha1.common_pb2 as common_pb2
import nebius.api.nebius.msp.spark.v1alpha1.preset_pb2 as preset_pb2
import nebius.api.nebius.msp.v1alpha1.resource as resource_1
import nebius.api.nebius.msp.v1alpha1.resource.template_pb2 as template_pb2
import nebius.base.protos.pb_enum as pb_enum
import nebius.api.nebius.msp.spark.v1alpha1.job_pb2 as job_pb2
import nebius.api.nebius.msp.spark.v1alpha1.job_service_pb2 as job_service_pb2
import nebius.api.nebius.msp.spark.v1alpha1.session_pb2 as session_pb2
import nebius.api.nebius.msp.spark.v1alpha1.session_service_pb2 as session_service_pb2
#@ local imports here @#

# file: nebius/msp/spark/v1alpha1/cluster.proto
class Cluster(pb_classes.Message):
    __PB2_CLASS__ = cluster_pb2.Cluster
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.Cluster",cluster_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None" = None,
        spec: "ClusterSpec|cluster_pb2.ClusterSpec|None" = None,
        status: "ClusterStatus|cluster_pb2.ClusterStatus|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
        if status is not None:
            self.status = status
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "ClusterSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=ClusterSpec,
        )
    @spec.setter
    def spec(self, value: "ClusterSpec|cluster_pb2.ClusterSpec") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
    @builtins.property
    def status(self) -> "ClusterStatus":
        return super()._get_field("status", explicit_presence=False,
        wrap=ClusterStatus,
        )
    @status.setter
    def status(self, value: "ClusterStatus|cluster_pb2.ClusterStatus") -> None:
        return super()._set_field("status",value,explicit_presence=False,
        )
    
class ClusterSpec(pb_classes.Message):
    __PB2_CLASS__ = cluster_pb2.ClusterSpec
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ClusterSpec",cluster_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class __OneOfClass__description__(pb_classes.OneOf):
        name: builtins.str= "_description"
        
        def __init__(self, msg: "ClusterSpec") -> None:
            super().__init__()
            self._message: "ClusterSpec" = msg
    
    class __OneOfClass__description_description__(__OneOfClass__description__):
        field: typing.Literal["description"] = "description"
        
        def __init__(self, msg: "ClusterSpec") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.description
    
    @builtins.property
    def _description(self) -> __OneOfClass__description_description__|None:
        field_name: str|None = super().which_field_in_oneof("_description")
        match field_name:
            case "description":
                return self.__OneOfClass__description_description__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        description: "builtins.str|None" = None,
        limits: "Limits|cluster_pb2.Limits|None" = None,
        authorization: "Password|cluster_pb2.Password|None" = None,
        service_account_id: "builtins.str|None" = None,
        network_id: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if description is not None:
            self.description = description
        if limits is not None:
            self.limits = limits
        if authorization is not None:
            self.authorization = authorization
        if service_account_id is not None:
            self.service_account_id = service_account_id
        if network_id is not None:
            self.network_id = network_id
    
    @builtins.property
    def description(self) -> "builtins.str|None":
        return super()._get_field("description", explicit_presence=True,
        )
    @description.setter
    def description(self, value: "builtins.str|None") -> None:
        return super()._set_field("description",value,explicit_presence=True,
        )
    
    @builtins.property
    def limits(self) -> "Limits":
        return super()._get_field("limits", explicit_presence=False,
        wrap=Limits,
        )
    @limits.setter
    def limits(self, value: "Limits|cluster_pb2.Limits") -> None:
        return super()._set_field("limits",value,explicit_presence=False,
        )
    
    @builtins.property
    def authorization(self) -> "Password":
        return super()._get_field("authorization", explicit_presence=False,
        wrap=Password,
        )
    @authorization.setter
    def authorization(self, value: "Password|cluster_pb2.Password") -> None:
        return super()._set_field("authorization",value,explicit_presence=False,
        )
    
    @builtins.property
    def service_account_id(self) -> "builtins.str":
        return super()._get_field("service_account_id", explicit_presence=False,
        )
    @service_account_id.setter
    def service_account_id(self, value: "builtins.str") -> None:
        return super()._set_field("service_account_id",value,explicit_presence=False,
        )
    
    @builtins.property
    def network_id(self) -> "builtins.str":
        return super()._get_field("network_id", explicit_presence=False,
        )
    @network_id.setter
    def network_id(self, value: "builtins.str") -> None:
        return super()._set_field("network_id",value,explicit_presence=False,
        )
    
class ClusterStatus(pb_classes.Message):
    __PB2_CLASS__ = cluster_pb2.ClusterStatus
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ClusterStatus",cluster_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class __OneOfClass__history_server_endpoint__(pb_classes.OneOf):
        name: builtins.str= "_history_server_endpoint"
        
        def __init__(self, msg: "ClusterStatus") -> None:
            super().__init__()
            self._message: "ClusterStatus" = msg
    
    class __OneOfClass__history_server_endpoint_history_server_endpoint__(__OneOfClass__history_server_endpoint__):
        field: typing.Literal["history_server_endpoint"] = "history_server_endpoint"
        
        def __init__(self, msg: "ClusterStatus") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.history_server_endpoint
    
    @builtins.property
    def _history_server_endpoint(self) -> __OneOfClass__history_server_endpoint_history_server_endpoint__|None:
        field_name: str|None = super().which_field_in_oneof("_history_server_endpoint")
        match field_name:
            case "history_server_endpoint":
                return self.__OneOfClass__history_server_endpoint_history_server_endpoint__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        phase: "v1alpha1_1.ClusterStatus.Phase|cluster_pb2_1.ClusterStatus.Phase|None" = None,
        state: "v1alpha1_1.ClusterStatus.State|cluster_pb2_1.ClusterStatus.State|None" = None,
        history_server_endpoint: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if phase is not None:
            self.phase = phase
        if state is not None:
            self.state = state
        if history_server_endpoint is not None:
            self.history_server_endpoint = history_server_endpoint
    
    @builtins.property
    def phase(self) -> "v1alpha1_1.ClusterStatus.Phase":
        return super()._get_field("phase", explicit_presence=False,
        wrap=v1alpha1_1.ClusterStatus.Phase,
        )
    @phase.setter
    def phase(self, value: "v1alpha1_1.ClusterStatus.Phase|cluster_pb2_1.ClusterStatus.Phase") -> None:
        return super()._set_field("phase",value,explicit_presence=False,
        )
    
    @builtins.property
    def state(self) -> "v1alpha1_1.ClusterStatus.State":
        return super()._get_field("state", explicit_presence=False,
        wrap=v1alpha1_1.ClusterStatus.State,
        )
    @state.setter
    def state(self, value: "v1alpha1_1.ClusterStatus.State|cluster_pb2_1.ClusterStatus.State") -> None:
        return super()._set_field("state",value,explicit_presence=False,
        )
    
    @builtins.property
    def history_server_endpoint(self) -> "builtins.str|None":
        return super()._get_field("history_server_endpoint", explicit_presence=True,
        )
    @history_server_endpoint.setter
    def history_server_endpoint(self, value: "builtins.str|None") -> None:
        return super()._set_field("history_server_endpoint",value,explicit_presence=True,
        )
    
class Limits(pb_classes.Message):
    __PB2_CLASS__ = cluster_pb2.Limits
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.Limits",cluster_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        cpu: "builtins.int|None" = None,
        memory_gibibytes: "builtins.int|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if cpu is not None:
            self.cpu = cpu
        if memory_gibibytes is not None:
            self.memory_gibibytes = memory_gibibytes
    
    @builtins.property
    def cpu(self) -> "builtins.int":
        return super()._get_field("cpu", explicit_presence=False,
        )
    @cpu.setter
    def cpu(self, value: "builtins.int") -> None:
        return super()._set_field("cpu",value,explicit_presence=False,
        )
    
    @builtins.property
    def memory_gibibytes(self) -> "builtins.int":
        return super()._get_field("memory_gibibytes", explicit_presence=False,
        )
    @memory_gibibytes.setter
    def memory_gibibytes(self, value: "builtins.int") -> None:
        return super()._set_field("memory_gibibytes",value,explicit_presence=False,
        )
    
class Password(pb_classes.Message):
    __PB2_CLASS__ = cluster_pb2.Password
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.Password",cluster_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        password: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if password is not None:
            self.password = password
    
    @builtins.property
    def password(self) -> "builtins.str":
        return super()._get_field("password", explicit_presence=False,
        )
    @password.setter
    def password(self, value: "builtins.str") -> None:
        return super()._set_field("password",value,explicit_presence=False,
        )
    
# file: nebius/msp/spark/v1alpha1/cluster_service.proto
class GetClusterRequest(pb_classes.Message):
    __PB2_CLASS__ = cluster_service_pb2.GetClusterRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.GetClusterRequest",cluster_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if id is not None:
            self.id = id
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    
class GetClusterByNameRequest(pb_classes.Message):
    __PB2_CLASS__ = cluster_service_pb2.GetClusterByNameRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.GetClusterByNameRequest",cluster_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        parent_id: "builtins.str|None" = None,
        name: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if parent_id is not None:
            self.parent_id = parent_id
        if name is not None:
            self.name = name
    
    @builtins.property
    def parent_id(self) -> "builtins.str":
        return super()._get_field("parent_id", explicit_presence=False,
        )
    @parent_id.setter
    def parent_id(self, value: "builtins.str") -> None:
        return super()._set_field("parent_id",value,explicit_presence=False,
        )
    
    @builtins.property
    def name(self) -> "builtins.str":
        return super()._get_field("name", explicit_presence=False,
        )
    @name.setter
    def name(self, value: "builtins.str") -> None:
        return super()._set_field("name",value,explicit_presence=False,
        )
    
class ListClustersRequest(pb_classes.Message):
    __PB2_CLASS__ = cluster_service_pb2.ListClustersRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ListClustersRequest",cluster_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        parent_id: "builtins.str|None" = None,
        page_size: "builtins.int|None" = None,
        page_token: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if parent_id is not None:
            self.parent_id = parent_id
        if page_size is not None:
            self.page_size = page_size
        if page_token is not None:
            self.page_token = page_token
    
    @builtins.property
    def parent_id(self) -> "builtins.str":
        return super()._get_field("parent_id", explicit_presence=False,
        )
    @parent_id.setter
    def parent_id(self, value: "builtins.str") -> None:
        return super()._set_field("parent_id",value,explicit_presence=False,
        )
    
    @builtins.property
    def page_size(self) -> "builtins.int":
        return super()._get_field("page_size", explicit_presence=False,
        )
    @page_size.setter
    def page_size(self, value: "builtins.int") -> None:
        return super()._set_field("page_size",value,explicit_presence=False,
        )
    
    @builtins.property
    def page_token(self) -> "builtins.str":
        return super()._get_field("page_token", explicit_presence=False,
        )
    @page_token.setter
    def page_token(self, value: "builtins.str") -> None:
        return super()._set_field("page_token",value,explicit_presence=False,
        )
    
class ListClustersResponse(pb_classes.Message):
    __PB2_CLASS__ = cluster_service_pb2.ListClustersResponse
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ListClustersResponse",cluster_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class __OneOfClass__next_page_token__(pb_classes.OneOf):
        name: builtins.str= "_next_page_token"
        
        def __init__(self, msg: "ListClustersResponse") -> None:
            super().__init__()
            self._message: "ListClustersResponse" = msg
    
    class __OneOfClass__next_page_token_next_page_token__(__OneOfClass__next_page_token__):
        field: typing.Literal["next_page_token"] = "next_page_token"
        
        def __init__(self, msg: "ListClustersResponse") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.next_page_token
    
    @builtins.property
    def _next_page_token(self) -> __OneOfClass__next_page_token_next_page_token__|None:
        field_name: str|None = super().which_field_in_oneof("_next_page_token")
        match field_name:
            case "next_page_token":
                return self.__OneOfClass__next_page_token_next_page_token__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        items: "abc.Iterable[Cluster]|None" = None,
        next_page_token: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if items is not None:
            self.items = items
        if next_page_token is not None:
            self.next_page_token = next_page_token
    
    @builtins.property
    def items(self) -> "abc.MutableSequence[Cluster]":
        return super()._get_field("items", explicit_presence=False,
        wrap=pb_classes.Repeated.with_wrap(Cluster,None),
        )
    @items.setter
    def items(self, value: "abc.Iterable[Cluster]") -> None:
        return super()._set_field("items",value,explicit_presence=False,
        )
    
    @builtins.property
    def next_page_token(self) -> "builtins.str|None":
        return super()._get_field("next_page_token", explicit_presence=True,
        )
    @next_page_token.setter
    def next_page_token(self, value: "builtins.str|None") -> None:
        return super()._set_field("next_page_token",value,explicit_presence=True,
        )
    
class CreateClusterRequest(pb_classes.Message):
    __PB2_CLASS__ = cluster_service_pb2.CreateClusterRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.CreateClusterRequest",cluster_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None" = None,
        spec: "ClusterSpec|cluster_pb2.ClusterSpec|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "ClusterSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=ClusterSpec,
        )
    @spec.setter
    def spec(self, value: "ClusterSpec|cluster_pb2.ClusterSpec") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
class UpdateClusterRequest(pb_classes.Message):
    __PB2_CLASS__ = cluster_service_pb2.UpdateClusterRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.UpdateClusterRequest",cluster_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None" = None,
        spec: "ClusterSpec|cluster_pb2.ClusterSpec|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "ClusterSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=ClusterSpec,
        )
    @spec.setter
    def spec(self, value: "ClusterSpec|cluster_pb2.ClusterSpec") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
class DeleteClusterRequest(pb_classes.Message):
    __PB2_CLASS__ = cluster_service_pb2.DeleteClusterRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.DeleteClusterRequest",cluster_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if id is not None:
            self.id = id
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    

class ClusterServiceClient(client.Client):
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.ServiceDescriptor](".nebius.msp.spark.v1alpha1.ClusterService",cluster_service_pb2.DESCRIPTOR,descriptor_1.ServiceDescriptor)
    __service_name__ = ".nebius.msp.spark.v1alpha1.ClusterService"
    __operation_type__ = v1_1.Operation
    
    def get(self,
        request: "GetClusterRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["GetClusterRequest","Cluster"]:
        return super().request(
            method="Get",
            request=request,
            result_pb2_class=cluster_pb2.Cluster,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
        )
    
    def get_by_name(self,
        request: "GetClusterByNameRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["GetClusterByNameRequest","Cluster"]:
        return super().request(
            method="GetByName",
            request=request,
            result_pb2_class=cluster_pb2.Cluster,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
        )
    
    def list(self,
        request: "ListClustersRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["ListClustersRequest","ListClustersResponse"]:
        return super().request(
            method="List",
            request=request,
            result_pb2_class=cluster_service_pb2.ListClustersResponse,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
        )
    
    def create(self,
        request: "CreateClusterRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["CreateClusterRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Create",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
            result_wrapper=operation.Operation,
        )
    
    def update(self,
        request: "UpdateClusterRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["UpdateClusterRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Update",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
            result_wrapper=operation.Operation,
        )
    
    def delete(self,
        request: "DeleteClusterRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["DeleteClusterRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Delete",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
            result_wrapper=operation.Operation,
        )
    

# file: nebius/msp/spark/v1alpha1/common.proto
class PythonConfig(pb_classes.Message):
    __PB2_CLASS__ = common_pb2.PythonConfig
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.PythonConfig",common_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        requirements: "abc.Iterable[builtins.str]|None" = None,
        file_uris: "abc.Iterable[builtins.str]|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if requirements is not None:
            self.requirements = requirements
        if file_uris is not None:
            self.file_uris = file_uris
    
    @builtins.property
    def requirements(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("requirements", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @requirements.setter
    def requirements(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("requirements",value,explicit_presence=False,
        )
    
    @builtins.property
    def file_uris(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("file_uris", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @file_uris.setter
    def file_uris(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("file_uris",value,explicit_presence=False,
        )
    
class JavaConfig(pb_classes.Message):
    __PB2_CLASS__ = common_pb2.JavaConfig
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.JavaConfig",common_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        entrypoint_class: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if entrypoint_class is not None:
            self.entrypoint_class = entrypoint_class
    
    @builtins.property
    def entrypoint_class(self) -> "builtins.str":
        return super()._get_field("entrypoint_class", explicit_presence=False,
        )
    @entrypoint_class.setter
    def entrypoint_class(self, value: "builtins.str") -> None:
        return super()._set_field("entrypoint_class",value,explicit_presence=False,
        )
    
# file: nebius/msp/spark/v1alpha1/preset.proto
class DriverTemplateSpec(pb_classes.Message):
    __PB2_CLASS__ = preset_pb2.DriverTemplateSpec
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.DriverTemplateSpec",preset_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        disk: "resource_1.DiskSpec|template_pb2.DiskSpec|None" = None,
        resources: "resource_1.ResourcesSpec|template_pb2.ResourcesSpec|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if disk is not None:
            self.disk = disk
        if resources is not None:
            self.resources = resources
    
    @builtins.property
    def disk(self) -> "resource_1.DiskSpec":
        return super()._get_field("disk", explicit_presence=False,
        wrap=resource_1.DiskSpec,
        )
    @disk.setter
    def disk(self, value: "resource_1.DiskSpec|template_pb2.DiskSpec") -> None:
        return super()._set_field("disk",value,explicit_presence=False,
        )
    
    @builtins.property
    def resources(self) -> "resource_1.ResourcesSpec":
        return super()._get_field("resources", explicit_presence=False,
        wrap=resource_1.ResourcesSpec,
        )
    @resources.setter
    def resources(self, value: "resource_1.ResourcesSpec|template_pb2.ResourcesSpec") -> None:
        return super()._set_field("resources",value,explicit_presence=False,
        )
    
class DynamicAllocationSpec(pb_classes.Message):
    __PB2_CLASS__ = preset_pb2.DynamicAllocationSpec
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.DynamicAllocationSpec",preset_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        min: "builtins.int|None" = None,
        max: "builtins.int|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if min is not None:
            self.min = min
        if max is not None:
            self.max = max
    
    @builtins.property
    def min(self) -> "builtins.int":
        return super()._get_field("min", explicit_presence=False,
        )
    @min.setter
    def min(self, value: "builtins.int") -> None:
        return super()._set_field("min",value,explicit_presence=False,
        )
    
    @builtins.property
    def max(self) -> "builtins.int":
        return super()._get_field("max", explicit_presence=False,
        )
    @max.setter
    def max(self, value: "builtins.int") -> None:
        return super()._set_field("max",value,explicit_presence=False,
        )
    
class ExecutorTemplateSpec(pb_classes.Message):
    __PB2_CLASS__ = preset_pb2.ExecutorTemplateSpec
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ExecutorTemplateSpec",preset_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class __OneOfClass_hosts_spec__(pb_classes.OneOf):
        name: builtins.str= "hosts_spec"
        
        def __init__(self, msg: "ExecutorTemplateSpec") -> None:
            super().__init__()
            self._message: "ExecutorTemplateSpec" = msg
    
    class __OneOfClass_hosts_spec_hosts__(__OneOfClass_hosts_spec__):
        field: typing.Literal["hosts"] = "hosts"
        
        def __init__(self, msg: "ExecutorTemplateSpec") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "resource_1.HostSpec":
            return self._message.hosts
    
    class __OneOfClass_hosts_spec_hosts_dynamic_allocation__(__OneOfClass_hosts_spec__):
        field: typing.Literal["hosts_dynamic_allocation"] = "hosts_dynamic_allocation"
        
        def __init__(self, msg: "ExecutorTemplateSpec") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "DynamicAllocationSpec":
            return self._message.hosts_dynamic_allocation
    
    @builtins.property
    def hosts_spec(self) -> __OneOfClass_hosts_spec_hosts__|__OneOfClass_hosts_spec_hosts_dynamic_allocation__|None:
        field_name: str|None = super().which_field_in_oneof("hosts_spec")
        match field_name:
            case "hosts":
                return self.__OneOfClass_hosts_spec_hosts__(self)
            case "hosts_dynamic_allocation":
                return self.__OneOfClass_hosts_spec_hosts_dynamic_allocation__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        disk: "resource_1.DiskSpec|template_pb2.DiskSpec|None" = None,
        resources: "resource_1.ResourcesSpec|template_pb2.ResourcesSpec|None" = None,
        hosts: "resource_1.HostSpec|template_pb2.HostSpec|None" = None,
        hosts_dynamic_allocation: "DynamicAllocationSpec|preset_pb2.DynamicAllocationSpec|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if disk is not None:
            self.disk = disk
        if resources is not None:
            self.resources = resources
        if hosts is not None:
            self.hosts = hosts
        if hosts_dynamic_allocation is not None:
            self.hosts_dynamic_allocation = hosts_dynamic_allocation
    
    @builtins.property
    def disk(self) -> "resource_1.DiskSpec":
        return super()._get_field("disk", explicit_presence=False,
        wrap=resource_1.DiskSpec,
        )
    @disk.setter
    def disk(self, value: "resource_1.DiskSpec|template_pb2.DiskSpec") -> None:
        return super()._set_field("disk",value,explicit_presence=False,
        )
    
    @builtins.property
    def resources(self) -> "resource_1.ResourcesSpec":
        return super()._get_field("resources", explicit_presence=False,
        wrap=resource_1.ResourcesSpec,
        )
    @resources.setter
    def resources(self, value: "resource_1.ResourcesSpec|template_pb2.ResourcesSpec") -> None:
        return super()._set_field("resources",value,explicit_presence=False,
        )
    
    @builtins.property
    def hosts(self) -> "resource_1.HostSpec":
        return super()._get_field("hosts", explicit_presence=False,
        wrap=resource_1.HostSpec,
        )
    @hosts.setter
    def hosts(self, value: "resource_1.HostSpec|template_pb2.HostSpec") -> None:
        return super()._set_field("hosts",value,explicit_presence=False,
        )
    
    @builtins.property
    def hosts_dynamic_allocation(self) -> "DynamicAllocationSpec":
        return super()._get_field("hosts_dynamic_allocation", explicit_presence=False,
        wrap=DynamicAllocationSpec,
        )
    @hosts_dynamic_allocation.setter
    def hosts_dynamic_allocation(self, value: "DynamicAllocationSpec|preset_pb2.DynamicAllocationSpec") -> None:
        return super()._set_field("hosts_dynamic_allocation",value,explicit_presence=False,
        )
    
# file: nebius/msp/spark/v1alpha1/job.proto
class JobResultCode(pb_enum.Enum):
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.EnumDescriptor](".nebius.msp.spark.v1alpha1.JobResultCode",job_pb2.DESCRIPTOR,descriptor_1.EnumDescriptor)
    JOB_RESULT_CODE_UNSPECIFIED = 0
    SUCCEEDED = 1
    ERROR = 2

class Job(pb_classes.Message):
    __PB2_CLASS__ = job_pb2.Job
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.Job",job_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None" = None,
        spec: "JobSpec|job_pb2.JobSpec|None" = None,
        status: "JobStatus|job_pb2.JobStatus|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
        if status is not None:
            self.status = status
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "JobSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=JobSpec,
        )
    @spec.setter
    def spec(self, value: "JobSpec|job_pb2.JobSpec") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
    @builtins.property
    def status(self) -> "JobStatus":
        return super()._get_field("status", explicit_presence=False,
        wrap=JobStatus,
        )
    @status.setter
    def status(self, value: "JobStatus|job_pb2.JobStatus") -> None:
        return super()._set_field("status",value,explicit_presence=False,
        )
    
class JobSpec(pb_classes.Message):
    __PB2_CLASS__ = job_pb2.JobSpec
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.JobSpec",job_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class SparkConfEntry(pb_classes.Message):
        __PB2_CLASS__ = job_pb2.JobSpec.SparkConfEntry
        __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.JobSpec.SparkConfEntry",job_pb2.DESCRIPTOR,descriptor_1.Descriptor)
        
        def __init__(
            self,
            initial_message: message_1.Message|None = None,
            *,
            key: "builtins.str|None" = None,
            value: "builtins.str|None" = None,
        ) -> None:
            super().__init__(initial_message)
            if key is not None:
                self.key = key
            if value is not None:
                self.value = value
        
        @builtins.property
        def key(self) -> "builtins.str":
            return super()._get_field("key", explicit_presence=False,
            )
        @key.setter
        def key(self, value: "builtins.str") -> None:
            return super()._set_field("key",value,explicit_presence=False,
            )
        
        @builtins.property
        def value(self) -> "builtins.str":
            return super()._get_field("value", explicit_presence=False,
            )
        @value.setter
        def value(self, value: "builtins.str") -> None:
            return super()._set_field("value",value,explicit_presence=False,
            )
        
    
    class __OneOfClass_runtime_config__(pb_classes.OneOf):
        name: builtins.str= "runtime_config"
        
        def __init__(self, msg: "JobSpec") -> None:
            super().__init__()
            self._message: "JobSpec" = msg
    
    class __OneOfClass_runtime_config_python__(__OneOfClass_runtime_config__):
        field: typing.Literal["python"] = "python"
        
        def __init__(self, msg: "JobSpec") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "PythonConfig":
            return self._message.python
    
    class __OneOfClass_runtime_config_java__(__OneOfClass_runtime_config__):
        field: typing.Literal["java"] = "java"
        
        def __init__(self, msg: "JobSpec") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "JavaConfig":
            return self._message.java
    
    @builtins.property
    def runtime_config(self) -> __OneOfClass_runtime_config_python__|__OneOfClass_runtime_config_java__|None:
        field_name: str|None = super().which_field_in_oneof("runtime_config")
        match field_name:
            case "python":
                return self.__OneOfClass_runtime_config_python__(self)
            case "java":
                return self.__OneOfClass_runtime_config_java__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    class __OneOfClass__description__(pb_classes.OneOf):
        name: builtins.str= "_description"
        
        def __init__(self, msg: "JobSpec") -> None:
            super().__init__()
            self._message: "JobSpec" = msg
    
    class __OneOfClass__description_description__(__OneOfClass__description__):
        field: typing.Literal["description"] = "description"
        
        def __init__(self, msg: "JobSpec") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.description
    
    @builtins.property
    def _description(self) -> __OneOfClass__description_description__|None:
        field_name: str|None = super().which_field_in_oneof("_description")
        match field_name:
            case "description":
                return self.__OneOfClass__description_description__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        description: "builtins.str|None" = None,
        application_file_uri: "builtins.str|None" = None,
        driver: "DriverTemplateSpec|preset_pb2.DriverTemplateSpec|None" = None,
        executor: "ExecutorTemplateSpec|preset_pb2.ExecutorTemplateSpec|None" = None,
        spark_version: "builtins.str|None" = None,
        application_args: "abc.Iterable[builtins.str]|None" = None,
        file_uris: "abc.Iterable[builtins.str]|None" = None,
        jar_uris: "abc.Iterable[builtins.str]|None" = None,
        packages: "abc.Iterable[builtins.str]|None" = None,
        spark_conf: "abc.Mapping[builtins.str,builtins.str]|None" = None,
        python: "PythonConfig|common_pb2.PythonConfig|None" = None,
        java: "JavaConfig|common_pb2.JavaConfig|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if description is not None:
            self.description = description
        if application_file_uri is not None:
            self.application_file_uri = application_file_uri
        if driver is not None:
            self.driver = driver
        if executor is not None:
            self.executor = executor
        if spark_version is not None:
            self.spark_version = spark_version
        if application_args is not None:
            self.application_args = application_args
        if file_uris is not None:
            self.file_uris = file_uris
        if jar_uris is not None:
            self.jar_uris = jar_uris
        if packages is not None:
            self.packages = packages
        if spark_conf is not None:
            self.spark_conf = spark_conf
        if python is not None:
            self.python = python
        if java is not None:
            self.java = java
    
    @builtins.property
    def description(self) -> "builtins.str|None":
        return super()._get_field("description", explicit_presence=True,
        )
    @description.setter
    def description(self, value: "builtins.str|None") -> None:
        return super()._set_field("description",value,explicit_presence=True,
        )
    
    @builtins.property
    def application_file_uri(self) -> "builtins.str":
        return super()._get_field("application_file_uri", explicit_presence=False,
        )
    @application_file_uri.setter
    def application_file_uri(self, value: "builtins.str") -> None:
        return super()._set_field("application_file_uri",value,explicit_presence=False,
        )
    
    @builtins.property
    def driver(self) -> "DriverTemplateSpec":
        return super()._get_field("driver", explicit_presence=False,
        wrap=DriverTemplateSpec,
        )
    @driver.setter
    def driver(self, value: "DriverTemplateSpec|preset_pb2.DriverTemplateSpec") -> None:
        return super()._set_field("driver",value,explicit_presence=False,
        )
    
    @builtins.property
    def executor(self) -> "ExecutorTemplateSpec":
        return super()._get_field("executor", explicit_presence=False,
        wrap=ExecutorTemplateSpec,
        )
    @executor.setter
    def executor(self, value: "ExecutorTemplateSpec|preset_pb2.ExecutorTemplateSpec") -> None:
        return super()._set_field("executor",value,explicit_presence=False,
        )
    
    @builtins.property
    def spark_version(self) -> "builtins.str":
        return super()._get_field("spark_version", explicit_presence=False,
        )
    @spark_version.setter
    def spark_version(self, value: "builtins.str") -> None:
        return super()._set_field("spark_version",value,explicit_presence=False,
        )
    
    @builtins.property
    def application_args(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("application_args", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @application_args.setter
    def application_args(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("application_args",value,explicit_presence=False,
        )
    
    @builtins.property
    def file_uris(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("file_uris", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @file_uris.setter
    def file_uris(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("file_uris",value,explicit_presence=False,
        )
    
    @builtins.property
    def jar_uris(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("jar_uris", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @jar_uris.setter
    def jar_uris(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("jar_uris",value,explicit_presence=False,
        )
    
    @builtins.property
    def packages(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("packages", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @packages.setter
    def packages(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("packages",value,explicit_presence=False,
        )
    
    @builtins.property
    def spark_conf(self) -> "abc.MutableMapping[builtins.str,builtins.str]":
        return super()._get_field("spark_conf", explicit_presence=False,
        wrap=pb_classes.Map,
        )
    @spark_conf.setter
    def spark_conf(self, value: "abc.Mapping[builtins.str,builtins.str]") -> None:
        return super()._set_field("spark_conf",value,explicit_presence=False,
        )
    
    @builtins.property
    def python(self) -> "PythonConfig":
        return super()._get_field("python", explicit_presence=False,
        wrap=PythonConfig,
        )
    @python.setter
    def python(self, value: "PythonConfig|common_pb2.PythonConfig") -> None:
        return super()._set_field("python",value,explicit_presence=False,
        )
    
    @builtins.property
    def java(self) -> "JavaConfig":
        return super()._get_field("java", explicit_presence=False,
        wrap=JavaConfig,
        )
    @java.setter
    def java(self, value: "JavaConfig|common_pb2.JavaConfig") -> None:
        return super()._set_field("java",value,explicit_presence=False,
        )
    
class JobResultDetails(pb_classes.Message):
    __PB2_CLASS__ = job_pb2.JobResultDetails
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.JobResultDetails",job_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        code: "JobResultCode|job_pb2.JobResultCode|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if code is not None:
            self.code = code
    
    @builtins.property
    def code(self) -> "JobResultCode":
        return super()._get_field("code", explicit_presence=False,
        wrap=JobResultCode,
        )
    @code.setter
    def code(self, value: "JobResultCode|job_pb2.JobResultCode") -> None:
        return super()._set_field("code",value,explicit_presence=False,
        )
    
class JobStatus(pb_classes.Message):
    __PB2_CLASS__ = job_pb2.JobStatus
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.JobStatus",job_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class __OneOfClass__driver_endpoint__(pb_classes.OneOf):
        name: builtins.str= "_driver_endpoint"
        
        def __init__(self, msg: "JobStatus") -> None:
            super().__init__()
            self._message: "JobStatus" = msg
    
    class __OneOfClass__driver_endpoint_driver_endpoint__(__OneOfClass__driver_endpoint__):
        field: typing.Literal["driver_endpoint"] = "driver_endpoint"
        
        def __init__(self, msg: "JobStatus") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.driver_endpoint
    
    @builtins.property
    def _driver_endpoint(self) -> __OneOfClass__driver_endpoint_driver_endpoint__|None:
        field_name: str|None = super().which_field_in_oneof("_driver_endpoint")
        match field_name:
            case "driver_endpoint":
                return self.__OneOfClass__driver_endpoint_driver_endpoint__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        phase: "v1alpha1_1.ClusterStatus.Phase|cluster_pb2_1.ClusterStatus.Phase|None" = None,
        state: "v1alpha1_1.ClusterStatus.State|cluster_pb2_1.ClusterStatus.State|None" = None,
        driver_endpoint: "builtins.str|None" = None,
        driver_preset_details: "resource_1.PresetDetails|template_pb2.PresetDetails|None" = None,
        executor_preset_details: "resource_1.PresetDetails|template_pb2.PresetDetails|None" = None,
        result_details: "JobResultDetails|job_pb2.JobResultDetails|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if phase is not None:
            self.phase = phase
        if state is not None:
            self.state = state
        if driver_endpoint is not None:
            self.driver_endpoint = driver_endpoint
        if driver_preset_details is not None:
            self.driver_preset_details = driver_preset_details
        if executor_preset_details is not None:
            self.executor_preset_details = executor_preset_details
        if result_details is not None:
            self.result_details = result_details
    
    @builtins.property
    def phase(self) -> "v1alpha1_1.ClusterStatus.Phase":
        return super()._get_field("phase", explicit_presence=False,
        wrap=v1alpha1_1.ClusterStatus.Phase,
        )
    @phase.setter
    def phase(self, value: "v1alpha1_1.ClusterStatus.Phase|cluster_pb2_1.ClusterStatus.Phase") -> None:
        return super()._set_field("phase",value,explicit_presence=False,
        )
    
    @builtins.property
    def state(self) -> "v1alpha1_1.ClusterStatus.State":
        return super()._get_field("state", explicit_presence=False,
        wrap=v1alpha1_1.ClusterStatus.State,
        )
    @state.setter
    def state(self, value: "v1alpha1_1.ClusterStatus.State|cluster_pb2_1.ClusterStatus.State") -> None:
        return super()._set_field("state",value,explicit_presence=False,
        )
    
    @builtins.property
    def driver_endpoint(self) -> "builtins.str|None":
        return super()._get_field("driver_endpoint", explicit_presence=True,
        )
    @driver_endpoint.setter
    def driver_endpoint(self, value: "builtins.str|None") -> None:
        return super()._set_field("driver_endpoint",value,explicit_presence=True,
        )
    
    @builtins.property
    def driver_preset_details(self) -> "resource_1.PresetDetails":
        return super()._get_field("driver_preset_details", explicit_presence=False,
        wrap=resource_1.PresetDetails,
        )
    @driver_preset_details.setter
    def driver_preset_details(self, value: "resource_1.PresetDetails|template_pb2.PresetDetails") -> None:
        return super()._set_field("driver_preset_details",value,explicit_presence=False,
        )
    
    @builtins.property
    def executor_preset_details(self) -> "resource_1.PresetDetails":
        return super()._get_field("executor_preset_details", explicit_presence=False,
        wrap=resource_1.PresetDetails,
        )
    @executor_preset_details.setter
    def executor_preset_details(self, value: "resource_1.PresetDetails|template_pb2.PresetDetails") -> None:
        return super()._set_field("executor_preset_details",value,explicit_presence=False,
        )
    
    @builtins.property
    def result_details(self) -> "JobResultDetails":
        return super()._get_field("result_details", explicit_presence=False,
        wrap=JobResultDetails,
        )
    @result_details.setter
    def result_details(self, value: "JobResultDetails|job_pb2.JobResultDetails") -> None:
        return super()._set_field("result_details",value,explicit_presence=False,
        )
    
# file: nebius/msp/spark/v1alpha1/job_service.proto
class GetJobRequest(pb_classes.Message):
    __PB2_CLASS__ = job_service_pb2.GetJobRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.GetJobRequest",job_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if id is not None:
            self.id = id
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    
class ListJobsRequest(pb_classes.Message):
    __PB2_CLASS__ = job_service_pb2.ListJobsRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ListJobsRequest",job_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        parent_id: "builtins.str|None" = None,
        page_size: "builtins.int|None" = None,
        page_token: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if parent_id is not None:
            self.parent_id = parent_id
        if page_size is not None:
            self.page_size = page_size
        if page_token is not None:
            self.page_token = page_token
    
    @builtins.property
    def parent_id(self) -> "builtins.str":
        return super()._get_field("parent_id", explicit_presence=False,
        )
    @parent_id.setter
    def parent_id(self, value: "builtins.str") -> None:
        return super()._set_field("parent_id",value,explicit_presence=False,
        )
    
    @builtins.property
    def page_size(self) -> "builtins.int":
        return super()._get_field("page_size", explicit_presence=False,
        )
    @page_size.setter
    def page_size(self, value: "builtins.int") -> None:
        return super()._set_field("page_size",value,explicit_presence=False,
        )
    
    @builtins.property
    def page_token(self) -> "builtins.str":
        return super()._get_field("page_token", explicit_presence=False,
        )
    @page_token.setter
    def page_token(self, value: "builtins.str") -> None:
        return super()._set_field("page_token",value,explicit_presence=False,
        )
    
class ListJobsResponse(pb_classes.Message):
    __PB2_CLASS__ = job_service_pb2.ListJobsResponse
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ListJobsResponse",job_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class __OneOfClass__next_page_token__(pb_classes.OneOf):
        name: builtins.str= "_next_page_token"
        
        def __init__(self, msg: "ListJobsResponse") -> None:
            super().__init__()
            self._message: "ListJobsResponse" = msg
    
    class __OneOfClass__next_page_token_next_page_token__(__OneOfClass__next_page_token__):
        field: typing.Literal["next_page_token"] = "next_page_token"
        
        def __init__(self, msg: "ListJobsResponse") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.next_page_token
    
    @builtins.property
    def _next_page_token(self) -> __OneOfClass__next_page_token_next_page_token__|None:
        field_name: str|None = super().which_field_in_oneof("_next_page_token")
        match field_name:
            case "next_page_token":
                return self.__OneOfClass__next_page_token_next_page_token__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        items: "abc.Iterable[Job]|None" = None,
        next_page_token: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if items is not None:
            self.items = items
        if next_page_token is not None:
            self.next_page_token = next_page_token
    
    @builtins.property
    def items(self) -> "abc.MutableSequence[Job]":
        return super()._get_field("items", explicit_presence=False,
        wrap=pb_classes.Repeated.with_wrap(Job,None),
        )
    @items.setter
    def items(self, value: "abc.Iterable[Job]") -> None:
        return super()._set_field("items",value,explicit_presence=False,
        )
    
    @builtins.property
    def next_page_token(self) -> "builtins.str|None":
        return super()._get_field("next_page_token", explicit_presence=True,
        )
    @next_page_token.setter
    def next_page_token(self, value: "builtins.str|None") -> None:
        return super()._set_field("next_page_token",value,explicit_presence=True,
        )
    
class CreateJobRequest(pb_classes.Message):
    __PB2_CLASS__ = job_service_pb2.CreateJobRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.CreateJobRequest",job_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None" = None,
        spec: "JobSpec|job_pb2.JobSpec|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "JobSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=JobSpec,
        )
    @spec.setter
    def spec(self, value: "JobSpec|job_pb2.JobSpec") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
class CancelJobRequest(pb_classes.Message):
    __PB2_CLASS__ = job_service_pb2.CancelJobRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.CancelJobRequest",job_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if id is not None:
            self.id = id
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    

class JobServiceClient(client.Client):
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.ServiceDescriptor](".nebius.msp.spark.v1alpha1.JobService",job_service_pb2.DESCRIPTOR,descriptor_1.ServiceDescriptor)
    __service_name__ = ".nebius.msp.spark.v1alpha1.JobService"
    __operation_type__ = v1_1.Operation
    
    def get(self,
        request: "GetJobRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["GetJobRequest","Job"]:
        return super().request(
            method="Get",
            request=request,
            result_pb2_class=job_pb2.Job,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
        )
    
    def list(self,
        request: "ListJobsRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["ListJobsRequest","ListJobsResponse"]:
        return super().request(
            method="List",
            request=request,
            result_pb2_class=job_service_pb2.ListJobsResponse,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
        )
    
    def create(self,
        request: "CreateJobRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["CreateJobRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Create",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
            result_wrapper=operation.Operation,
        )
    
    def cancel(self,
        request: "CancelJobRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["CancelJobRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Cancel",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
            result_wrapper=operation.Operation,
        )
    

# file: nebius/msp/spark/v1alpha1/session.proto
class Session(pb_classes.Message):
    __PB2_CLASS__ = session_pb2.Session
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.Session",session_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None" = None,
        spec: "SessionSpec|session_pb2.SessionSpec|None" = None,
        status: "SessionStatus|session_pb2.SessionStatus|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
        if status is not None:
            self.status = status
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "SessionSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=SessionSpec,
        )
    @spec.setter
    def spec(self, value: "SessionSpec|session_pb2.SessionSpec") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
    @builtins.property
    def status(self) -> "SessionStatus":
        return super()._get_field("status", explicit_presence=False,
        wrap=SessionStatus,
        )
    @status.setter
    def status(self, value: "SessionStatus|session_pb2.SessionStatus") -> None:
        return super()._set_field("status",value,explicit_presence=False,
        )
    
class SessionSpec(pb_classes.Message):
    __PB2_CLASS__ = session_pb2.SessionSpec
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.SessionSpec",session_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class SparkConfEntry(pb_classes.Message):
        __PB2_CLASS__ = session_pb2.SessionSpec.SparkConfEntry
        __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.SessionSpec.SparkConfEntry",session_pb2.DESCRIPTOR,descriptor_1.Descriptor)
        
        def __init__(
            self,
            initial_message: message_1.Message|None = None,
            *,
            key: "builtins.str|None" = None,
            value: "builtins.str|None" = None,
        ) -> None:
            super().__init__(initial_message)
            if key is not None:
                self.key = key
            if value is not None:
                self.value = value
        
        @builtins.property
        def key(self) -> "builtins.str":
            return super()._get_field("key", explicit_presence=False,
            )
        @key.setter
        def key(self, value: "builtins.str") -> None:
            return super()._set_field("key",value,explicit_presence=False,
            )
        
        @builtins.property
        def value(self) -> "builtins.str":
            return super()._get_field("value", explicit_presence=False,
            )
        @value.setter
        def value(self, value: "builtins.str") -> None:
            return super()._set_field("value",value,explicit_presence=False,
            )
        
    
    class __OneOfClass__description__(pb_classes.OneOf):
        name: builtins.str= "_description"
        
        def __init__(self, msg: "SessionSpec") -> None:
            super().__init__()
            self._message: "SessionSpec" = msg
    
    class __OneOfClass__description_description__(__OneOfClass__description__):
        field: typing.Literal["description"] = "description"
        
        def __init__(self, msg: "SessionSpec") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.description
    
    @builtins.property
    def _description(self) -> __OneOfClass__description_description__|None:
        field_name: str|None = super().which_field_in_oneof("_description")
        match field_name:
            case "description":
                return self.__OneOfClass__description_description__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        description: "builtins.str|None" = None,
        driver: "DriverTemplateSpec|preset_pb2.DriverTemplateSpec|None" = None,
        executor: "ExecutorTemplateSpec|preset_pb2.ExecutorTemplateSpec|None" = None,
        spark_version: "builtins.str|None" = None,
        file_uris: "abc.Iterable[builtins.str]|None" = None,
        jar_uris: "abc.Iterable[builtins.str]|None" = None,
        packages: "abc.Iterable[builtins.str]|None" = None,
        spark_conf: "abc.Mapping[builtins.str,builtins.str]|None" = None,
        python: "PythonConfig|common_pb2.PythonConfig|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if description is not None:
            self.description = description
        if driver is not None:
            self.driver = driver
        if executor is not None:
            self.executor = executor
        if spark_version is not None:
            self.spark_version = spark_version
        if file_uris is not None:
            self.file_uris = file_uris
        if jar_uris is not None:
            self.jar_uris = jar_uris
        if packages is not None:
            self.packages = packages
        if spark_conf is not None:
            self.spark_conf = spark_conf
        if python is not None:
            self.python = python
    
    @builtins.property
    def description(self) -> "builtins.str|None":
        return super()._get_field("description", explicit_presence=True,
        )
    @description.setter
    def description(self, value: "builtins.str|None") -> None:
        return super()._set_field("description",value,explicit_presence=True,
        )
    
    @builtins.property
    def driver(self) -> "DriverTemplateSpec":
        return super()._get_field("driver", explicit_presence=False,
        wrap=DriverTemplateSpec,
        )
    @driver.setter
    def driver(self, value: "DriverTemplateSpec|preset_pb2.DriverTemplateSpec") -> None:
        return super()._set_field("driver",value,explicit_presence=False,
        )
    
    @builtins.property
    def executor(self) -> "ExecutorTemplateSpec":
        return super()._get_field("executor", explicit_presence=False,
        wrap=ExecutorTemplateSpec,
        )
    @executor.setter
    def executor(self, value: "ExecutorTemplateSpec|preset_pb2.ExecutorTemplateSpec") -> None:
        return super()._set_field("executor",value,explicit_presence=False,
        )
    
    @builtins.property
    def spark_version(self) -> "builtins.str":
        return super()._get_field("spark_version", explicit_presence=False,
        )
    @spark_version.setter
    def spark_version(self, value: "builtins.str") -> None:
        return super()._set_field("spark_version",value,explicit_presence=False,
        )
    
    @builtins.property
    def file_uris(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("file_uris", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @file_uris.setter
    def file_uris(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("file_uris",value,explicit_presence=False,
        )
    
    @builtins.property
    def jar_uris(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("jar_uris", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @jar_uris.setter
    def jar_uris(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("jar_uris",value,explicit_presence=False,
        )
    
    @builtins.property
    def packages(self) -> "abc.MutableSequence[builtins.str]":
        return super()._get_field("packages", explicit_presence=False,
        wrap=pb_classes.Repeated,
        )
    @packages.setter
    def packages(self, value: "abc.Iterable[builtins.str]") -> None:
        return super()._set_field("packages",value,explicit_presence=False,
        )
    
    @builtins.property
    def spark_conf(self) -> "abc.MutableMapping[builtins.str,builtins.str]":
        return super()._get_field("spark_conf", explicit_presence=False,
        wrap=pb_classes.Map,
        )
    @spark_conf.setter
    def spark_conf(self, value: "abc.Mapping[builtins.str,builtins.str]") -> None:
        return super()._set_field("spark_conf",value,explicit_presence=False,
        )
    
    @builtins.property
    def python(self) -> "PythonConfig":
        return super()._get_field("python", explicit_presence=False,
        wrap=PythonConfig,
        )
    @python.setter
    def python(self, value: "PythonConfig|common_pb2.PythonConfig") -> None:
        return super()._set_field("python",value,explicit_presence=False,
        )
    
class SessionStatus(pb_classes.Message):
    __PB2_CLASS__ = session_pb2.SessionStatus
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.SessionStatus",session_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class __OneOfClass__spark_connect_endpoint__(pb_classes.OneOf):
        name: builtins.str= "_spark_connect_endpoint"
        
        def __init__(self, msg: "SessionStatus") -> None:
            super().__init__()
            self._message: "SessionStatus" = msg
    
    class __OneOfClass__spark_connect_endpoint_spark_connect_endpoint__(__OneOfClass__spark_connect_endpoint__):
        field: typing.Literal["spark_connect_endpoint"] = "spark_connect_endpoint"
        
        def __init__(self, msg: "SessionStatus") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.spark_connect_endpoint
    
    @builtins.property
    def _spark_connect_endpoint(self) -> __OneOfClass__spark_connect_endpoint_spark_connect_endpoint__|None:
        field_name: str|None = super().which_field_in_oneof("_spark_connect_endpoint")
        match field_name:
            case "spark_connect_endpoint":
                return self.__OneOfClass__spark_connect_endpoint_spark_connect_endpoint__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        phase: "v1alpha1_1.ClusterStatus.Phase|cluster_pb2_1.ClusterStatus.Phase|None" = None,
        state: "v1alpha1_1.ClusterStatus.State|cluster_pb2_1.ClusterStatus.State|None" = None,
        spark_connect_endpoint: "builtins.str|None" = None,
        driver_preset_details: "resource_1.PresetDetails|template_pb2.PresetDetails|None" = None,
        executor_preset_details: "resource_1.PresetDetails|template_pb2.PresetDetails|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if phase is not None:
            self.phase = phase
        if state is not None:
            self.state = state
        if spark_connect_endpoint is not None:
            self.spark_connect_endpoint = spark_connect_endpoint
        if driver_preset_details is not None:
            self.driver_preset_details = driver_preset_details
        if executor_preset_details is not None:
            self.executor_preset_details = executor_preset_details
    
    @builtins.property
    def phase(self) -> "v1alpha1_1.ClusterStatus.Phase":
        return super()._get_field("phase", explicit_presence=False,
        wrap=v1alpha1_1.ClusterStatus.Phase,
        )
    @phase.setter
    def phase(self, value: "v1alpha1_1.ClusterStatus.Phase|cluster_pb2_1.ClusterStatus.Phase") -> None:
        return super()._set_field("phase",value,explicit_presence=False,
        )
    
    @builtins.property
    def state(self) -> "v1alpha1_1.ClusterStatus.State":
        return super()._get_field("state", explicit_presence=False,
        wrap=v1alpha1_1.ClusterStatus.State,
        )
    @state.setter
    def state(self, value: "v1alpha1_1.ClusterStatus.State|cluster_pb2_1.ClusterStatus.State") -> None:
        return super()._set_field("state",value,explicit_presence=False,
        )
    
    @builtins.property
    def spark_connect_endpoint(self) -> "builtins.str|None":
        return super()._get_field("spark_connect_endpoint", explicit_presence=True,
        )
    @spark_connect_endpoint.setter
    def spark_connect_endpoint(self, value: "builtins.str|None") -> None:
        return super()._set_field("spark_connect_endpoint",value,explicit_presence=True,
        )
    
    @builtins.property
    def driver_preset_details(self) -> "resource_1.PresetDetails":
        return super()._get_field("driver_preset_details", explicit_presence=False,
        wrap=resource_1.PresetDetails,
        )
    @driver_preset_details.setter
    def driver_preset_details(self, value: "resource_1.PresetDetails|template_pb2.PresetDetails") -> None:
        return super()._set_field("driver_preset_details",value,explicit_presence=False,
        )
    
    @builtins.property
    def executor_preset_details(self) -> "resource_1.PresetDetails":
        return super()._get_field("executor_preset_details", explicit_presence=False,
        wrap=resource_1.PresetDetails,
        )
    @executor_preset_details.setter
    def executor_preset_details(self, value: "resource_1.PresetDetails|template_pb2.PresetDetails") -> None:
        return super()._set_field("executor_preset_details",value,explicit_presence=False,
        )
    
# file: nebius/msp/spark/v1alpha1/session_service.proto
class GetSessionRequest(pb_classes.Message):
    __PB2_CLASS__ = session_service_pb2.GetSessionRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.GetSessionRequest",session_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if id is not None:
            self.id = id
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    
class GetSessionByNameRequest(pb_classes.Message):
    __PB2_CLASS__ = session_service_pb2.GetSessionByNameRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.GetSessionByNameRequest",session_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        parent_id: "builtins.str|None" = None,
        name: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if parent_id is not None:
            self.parent_id = parent_id
        if name is not None:
            self.name = name
    
    @builtins.property
    def parent_id(self) -> "builtins.str":
        return super()._get_field("parent_id", explicit_presence=False,
        )
    @parent_id.setter
    def parent_id(self, value: "builtins.str") -> None:
        return super()._set_field("parent_id",value,explicit_presence=False,
        )
    
    @builtins.property
    def name(self) -> "builtins.str":
        return super()._get_field("name", explicit_presence=False,
        )
    @name.setter
    def name(self, value: "builtins.str") -> None:
        return super()._set_field("name",value,explicit_presence=False,
        )
    
class ListSessionsRequest(pb_classes.Message):
    __PB2_CLASS__ = session_service_pb2.ListSessionsRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ListSessionsRequest",session_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        parent_id: "builtins.str|None" = None,
        page_size: "builtins.int|None" = None,
        page_token: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if parent_id is not None:
            self.parent_id = parent_id
        if page_size is not None:
            self.page_size = page_size
        if page_token is not None:
            self.page_token = page_token
    
    @builtins.property
    def parent_id(self) -> "builtins.str":
        return super()._get_field("parent_id", explicit_presence=False,
        )
    @parent_id.setter
    def parent_id(self, value: "builtins.str") -> None:
        return super()._set_field("parent_id",value,explicit_presence=False,
        )
    
    @builtins.property
    def page_size(self) -> "builtins.int":
        return super()._get_field("page_size", explicit_presence=False,
        )
    @page_size.setter
    def page_size(self, value: "builtins.int") -> None:
        return super()._set_field("page_size",value,explicit_presence=False,
        )
    
    @builtins.property
    def page_token(self) -> "builtins.str":
        return super()._get_field("page_token", explicit_presence=False,
        )
    @page_token.setter
    def page_token(self, value: "builtins.str") -> None:
        return super()._set_field("page_token",value,explicit_presence=False,
        )
    
class ListSessionsResponse(pb_classes.Message):
    __PB2_CLASS__ = session_service_pb2.ListSessionsResponse
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.ListSessionsResponse",session_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    class __OneOfClass__next_page_token__(pb_classes.OneOf):
        name: builtins.str= "_next_page_token"
        
        def __init__(self, msg: "ListSessionsResponse") -> None:
            super().__init__()
            self._message: "ListSessionsResponse" = msg
    
    class __OneOfClass__next_page_token_next_page_token__(__OneOfClass__next_page_token__):
        field: typing.Literal["next_page_token"] = "next_page_token"
        
        def __init__(self, msg: "ListSessionsResponse") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.str":
            return self._message.next_page_token
    
    @builtins.property
    def _next_page_token(self) -> __OneOfClass__next_page_token_next_page_token__|None:
        field_name: str|None = super().which_field_in_oneof("_next_page_token")
        match field_name:
            case "next_page_token":
                return self.__OneOfClass__next_page_token_next_page_token__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        items: "abc.Iterable[Session]|None" = None,
        next_page_token: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if items is not None:
            self.items = items
        if next_page_token is not None:
            self.next_page_token = next_page_token
    
    @builtins.property
    def items(self) -> "abc.MutableSequence[Session]":
        return super()._get_field("items", explicit_presence=False,
        wrap=pb_classes.Repeated.with_wrap(Session,None),
        )
    @items.setter
    def items(self, value: "abc.Iterable[Session]") -> None:
        return super()._set_field("items",value,explicit_presence=False,
        )
    
    @builtins.property
    def next_page_token(self) -> "builtins.str|None":
        return super()._get_field("next_page_token", explicit_presence=True,
        )
    @next_page_token.setter
    def next_page_token(self, value: "builtins.str|None") -> None:
        return super()._set_field("next_page_token",value,explicit_presence=True,
        )
    
class CreateSessionRequest(pb_classes.Message):
    __PB2_CLASS__ = session_service_pb2.CreateSessionRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.CreateSessionRequest",session_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None" = None,
        spec: "SessionSpec|session_pb2.SessionSpec|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "SessionSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=SessionSpec,
        )
    @spec.setter
    def spec(self, value: "SessionSpec|session_pb2.SessionSpec") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
class DeleteSessionRequest(pb_classes.Message):
    __PB2_CLASS__ = session_service_pb2.DeleteSessionRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.msp.spark.v1alpha1.DeleteSessionRequest",session_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None" = None,
    ) -> None:
        super().__init__(initial_message)
        if id is not None:
            self.id = id
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    

class SessionServiceClient(client.Client):
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.ServiceDescriptor](".nebius.msp.spark.v1alpha1.SessionService",session_service_pb2.DESCRIPTOR,descriptor_1.ServiceDescriptor)
    __service_name__ = ".nebius.msp.spark.v1alpha1.SessionService"
    __operation_type__ = v1_1.Operation
    
    def get(self,
        request: "GetSessionRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["GetSessionRequest","Session"]:
        return super().request(
            method="Get",
            request=request,
            result_pb2_class=session_pb2.Session,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
        )
    
    def get_by_name(self,
        request: "GetSessionByNameRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["GetSessionByNameRequest","Session"]:
        return super().request(
            method="GetByName",
            request=request,
            result_pb2_class=session_pb2.Session,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
        )
    
    def list(self,
        request: "ListSessionsRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["ListSessionsRequest","ListSessionsResponse"]:
        return super().request(
            method="List",
            request=request,
            result_pb2_class=session_service_pb2.ListSessionsResponse,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
        )
    
    def create(self,
        request: "CreateSessionRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["CreateSessionRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Create",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
            result_wrapper=operation.Operation,
        )
    
    def delete(self,
        request: "DeleteSessionRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        wait_for_ready: builtins.bool | None = None,
        compression: grpc.Compression | None = None,
    ) -> request_1.Request["DeleteSessionRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Delete",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            wait_for_ready=wait_for_ready,
            compression=compression,
            result_wrapper=operation.Operation,
        )
    

__all__ = [
    #@ local import names here @#
    "Cluster",
    "ClusterSpec",
    "ClusterStatus",
    "Limits",
    "Password",
    "GetClusterRequest",
    "GetClusterByNameRequest",
    "ListClustersRequest",
    "ListClustersResponse",
    "CreateClusterRequest",
    "UpdateClusterRequest",
    "DeleteClusterRequest",
    "ClusterServiceClient",
    "PythonConfig",
    "JavaConfig",
    "DriverTemplateSpec",
    "DynamicAllocationSpec",
    "ExecutorTemplateSpec",
    "JobResultCode",
    "Job",
    "JobSpec",
    "JobResultDetails",
    "JobStatus",
    "GetJobRequest",
    "ListJobsRequest",
    "ListJobsResponse",
    "CreateJobRequest",
    "CancelJobRequest",
    "JobServiceClient",
    "Session",
    "SessionSpec",
    "SessionStatus",
    "GetSessionRequest",
    "GetSessionByNameRequest",
    "ListSessionsRequest",
    "ListSessionsResponse",
    "CreateSessionRequest",
    "DeleteSessionRequest",
    "SessionServiceClient",
]
